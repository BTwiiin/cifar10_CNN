{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e358bff6244ee35a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction to Computer Vision Project using Pre-trained ResNet101 on CIFAR-10 Dataset\n",
    "\n",
    "\n",
    "*Introduction:*\n",
    "\n",
    "Welcome to my computer vision project! In this project, we'll be leveraging the power of deep learning to tackle the task of image classification using the CIFAR-10 dataset. Our goal is to build an accurate image classifier capable of identifying objects in images across ten different classes.\n",
    "\n",
    "To achieve this, we'll be employing transfer learning, a technique that allows us to leverage pre-trained neural network architectures and adapt them to our specific task. Specifically, we'll be using the ResNet101 model, which has been pre-trained on the ImageNet dataset, a large-scale dataset with millions of labeled images across thousands of classes.\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
    "\n",
    "Our approach involves fine-tuning the pre-trained ResNet101 model on the CIFAR-10 dataset. This allows us to benefit from the generalization capabilities learned by the model on ImageNet while adapting it to the specific characteristics of our target dataset.\n",
    "\n",
    "In this project, we'll walk through the entire pipeline, from data preparation and preprocessing to model training, evaluation, and inference. By the end, we aim to have a robust image classifier capable of accurately predicting the classes of images from the CIFAR-10 dataset.\n",
    "\n",
    "Let's dive into the code and start building our image classification pipeline!\n",
    "\n",
    "\n",
    "Let's load CIFAR-10 dataset and divide it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:44:17.477351900Z",
     "start_time": "2024-04-07T13:44:16.866655300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a79e23b2b3003f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:44:17.882477800Z",
     "start_time": "2024-04-07T13:44:17.485351400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "X_valid = tf.data.Dataset.from_tensor_slices(X_valid)\n",
    "y_valid = tf.data.Dataset.from_tensor_slices(y_valid)\n",
    "X_test = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "y_test = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "train_dataset_raw = tf.data.Dataset.zip((X_train, y_train))\n",
    "valid_dataset_raw = tf.data.Dataset.zip((X_valid, y_valid))\n",
    "test_dataset_raw = tf.data.Dataset.zip((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08be41bd-5206-4959-9feb-84221b35dd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9051d3f5adc18f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data preprocessing\n",
    "\n",
    "ResNet-101 model expects 224x224 pixel images, and it also expects it to be scaled from 0 to 1, hopefully, each model provides `preprocess_input()` method, that can be used to preprocess input images. Keras provide a lot of ways to resize and rescale images, like `Upsampling2D` layer, `Lambda` layer and so on. These methods involve preprocessing data on the fly, that can slow down training. Another approach is to preprocess images before training and feed them into the model. I will go for the second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac61d79b94bcdd6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:44:19.608218Z",
     "start_time": "2024-04-07T13:44:19.594217100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(height=224, width=224, crop_to_aspect_ratio=True),\n",
    "    tf.keras.layers.Lambda(tf.keras.applications.resnet.preprocess_input)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34c678319de528",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training data shuffling and prefetching\n",
    "\n",
    "It is important to shuffle the training set, since `Gradient descent` works best, when instances of an existing data are independent and identically distributed, and shuffling insuring those conditions. There is a simple method called `shuffle()`, that will do all the work for us. After, I want to prefetch dataset, this insures that dataset will always be `n` batch ahead, meaning that, while the algorithm works on one batch, the dataset will work on the next batch to make it ready when the algorithm finishes with the current one. There is a `prefetch(1)` method, where 1 means => 1 batch ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a770c781465ed9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Speeding up training\n",
    "\n",
    "It could be done by utilizing `num_parallel_calls()` method when calling `map()`, also we can `cache()` the dataset context into RAM, but it can only be done, while dataset is small enough to fit into RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b048110b114396d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:44:20.897071500Z",
     "start_time": "2024-04-07T13:44:20.792553700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = train_dataset_raw.map(lambda X, y:(preprocess(X), y))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=3000, seed=42, reshuffle_each_iteration=False).batch(batch_size).prefetch(1)\n",
    "valid_dataset = valid_dataset_raw.map(lambda X, y:(preprocess(X), y)).batch(batch_size)\n",
    "test_dataset = test_dataset_raw.map(lambda X, y:(preprocess(X), y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a44f2e6c2461bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`reshuffle_each_iteration=False` is set to get the same order on a shuffled dataset for testing purposes, it is generally recommended to leave it as a default and use `repeat()` method to make `shuffle()` method generate new order each iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f21dcc450a8e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data augmentation\n",
    "\n",
    "It is a good way of addressing the problem of not enough training instances, but , I believe, 50000 instances is enough for my goals. If you are interested in it, there are several layers about which you can read in the Keras documentation: `RandomFlip()`, `RandomRotation()` and `RandomConstrany()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad85164461ed065",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading model\n",
    "\n",
    "Now we are ready to load ResNet101 model. We have to set `include_top=False`  to load model without fully connected top layers, so we will be able to put our own. After we need to add global average pooling layer and fully connected Dense layer with `softmax` activation function with 10 output units, which we've deleted by `include_top=False`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bae1cec12123fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T14:20:07.021966300Z",
     "start_time": "2024-04-07T14:19:44.088801500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.resnet.ResNet101(include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "drop = tf.keras.layers.Dropout(0.5)(avg)\n",
    "output = tf.keras.layers.Dense(10, activation=\"softmax\", dtype=\"float32\")(drop)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1422a7ab05af067",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Freezing low layers\n",
    "\n",
    "Since we've added new layers, their weights were initialized randomly, consequently model will make a lot of mistakes, so there will be large error gradient that may wreck the reused weights. In order to avoid this scenario, we can freeze the reused layers during the first epochs, to give time for the new layers to learn reasonable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62587a79aa9d1558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T14:20:47.301352100Z",
     "start_time": "2024-04-07T14:20:47.281350600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5511271ec619d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:04:43.368040Z",
     "start_time": "2024-04-07T14:25:11.909741700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1407/1407 [==============================] - 159s 97ms/step - loss: 1.6137 - accuracy: 0.8876 - val_loss: 1.0801 - val_accuracy: 0.9162\n",
      "Epoch 2/3\n",
      "1407/1407 [==============================] - 139s 94ms/step - loss: 1.2000 - accuracy: 0.9041 - val_loss: 1.0230 - val_accuracy: 0.9202\n",
      "Epoch 3/3\n",
      "1407/1407 [==============================] - 140s 95ms/step - loss: 0.7723 - accuracy: 0.9236 - val_loss: 0.9675 - val_accuracy: 0.9186\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0df1f09b9c2db08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:13:03.658722900Z",
     "start_time": "2024-04-07T17:06:01.124776Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 20s 63ms/step - loss: 1.0424 - accuracy: 0.9156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0423580408096313, 0.9156000018119812]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd90abf8b6f47d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After the first 2 epochs, this model managed to reach 92% validation accuracy and 90% training set accuracy, which is great result, but loss of 1 indicates, that model is not really confident when making predictions. I suggest to unfreeze some layers of ResNet101 to gain more insight on what is going on. \n",
    "I'm unfreezing layers 72 to the top. Also, adding some callbacks allows me to set as many epochs as I want, since ModelCheckpoint will save the best model for us and EarlyStopping will stop the simulation. Consequently, we may not bother about overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d89c2df84ce4281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T20:08:11.204028Z",
     "start_time": "2024-04-07T20:08:11.135820600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers[72:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "648917ab-2c11-44df-803e-91c8c09aa3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6, monitor=\"val_loss\", mode='min')\n",
    "lr_scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_v1.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e11d159fabd5b81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T20:10:23.392410100Z",
     "start_time": "2024-04-07T20:08:25.086663300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 474s 304ms/step - loss: 1.9846 - accuracy: 0.5706 - val_loss: 3.3088 - val_accuracy: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vshug\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 431s 304ms/step - loss: 1.1363 - accuracy: 0.6764 - val_loss: 0.7556 - val_accuracy: 0.7478\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 418s 296ms/step - loss: 0.6798 - accuracy: 0.7722 - val_loss: 0.6531 - val_accuracy: 0.7848\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 422s 298ms/step - loss: 0.5387 - accuracy: 0.8190 - val_loss: 0.5371 - val_accuracy: 0.8180\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 431s 305ms/step - loss: 0.4141 - accuracy: 0.8600 - val_loss: 0.4661 - val_accuracy: 0.8488\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 431s 304ms/step - loss: 0.3215 - accuracy: 0.8904 - val_loss: 0.5120 - val_accuracy: 0.8372\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 423s 299ms/step - loss: 0.2364 - accuracy: 0.9186 - val_loss: 0.5844 - val_accuracy: 0.8294\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 395s 279ms/step - loss: 0.1761 - accuracy: 0.9391 - val_loss: 0.5199 - val_accuracy: 0.8512\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 398s 282ms/step - loss: 0.0788 - accuracy: 0.9737 - val_loss: 0.4717 - val_accuracy: 0.8782\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 394s 279ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.5097 - val_accuracy: 0.8762\n",
      "Epoch 11/100\n",
      " 158/1407 [==>...........................] - ETA: 5:41 - loss: 0.0401 - accuracy: 0.9866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m      2\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, \n",
    "                    epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c29694dc-f08f-4839-9bc5-770549c6d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 22s 63ms/step - loss: 0.5156 - accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.515618085861206, 0.8349999785423279]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_v1.keras\")\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db50cc-a42d-4510-9478-211859adfeed",
   "metadata": {},
   "source": [
    "After 5th epoch model started to overfit a lot, so my first guess is that I've unfrozen too many layers. This model is twice more confident about its predictions, but at the same time it makes more mistakes. Also, I want to try experimenting with L2 regularization, instead of dropout, that should bound parameter values, which may help with overfitting. One more think is that I want to give more epochs to the first model and after unfreeze just a small amount of layers with lower learning rate.\n",
    "Here we may see the main disadvantage of Neural Networks in general, too much to bother about. Well, I set an outline on what I want to work now. I get back to you as soon as I find the best solution that works for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd861c6e-8904-496c-835f-ea5252830efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 120s 74ms/step - loss: 0.4969 - accuracy: 0.8371 - val_loss: 0.2608 - val_accuracy: 0.9158\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 105s 73ms/step - loss: 0.3661 - accuracy: 0.8819 - val_loss: 0.2660 - val_accuracy: 0.9130\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 107s 75ms/step - loss: 0.3618 - accuracy: 0.8837 - val_loss: 0.2584 - val_accuracy: 0.9166\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 109s 76ms/step - loss: 0.3644 - accuracy: 0.8877 - val_loss: 0.2599 - val_accuracy: 0.9174\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 110s 77ms/step - loss: 0.3599 - accuracy: 0.8891 - val_loss: 0.2684 - val_accuracy: 0.9150\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 111s 77ms/step - loss: 0.3661 - accuracy: 0.8889 - val_loss: 0.2592 - val_accuracy: 0.9164\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 111s 78ms/step - loss: 0.3266 - accuracy: 0.8975 - val_loss: 0.2562 - val_accuracy: 0.9202\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 141s 99ms/step - loss: 0.3148 - accuracy: 0.8990 - val_loss: 0.2643 - val_accuracy: 0.9154\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 128s 88ms/step - loss: 0.3061 - accuracy: 0.9011 - val_loss: 0.2530 - val_accuracy: 0.9186\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 120s 83ms/step - loss: 0.2975 - accuracy: 0.9015 - val_loss: 0.2583 - val_accuracy: 0.9152\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 108s 75ms/step - loss: 0.2982 - accuracy: 0.9030 - val_loss: 0.2492 - val_accuracy: 0.9190\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 111s 78ms/step - loss: 0.2986 - accuracy: 0.9014 - val_loss: 0.2556 - val_accuracy: 0.9154\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 114s 79ms/step - loss: 0.2942 - accuracy: 0.9030 - val_loss: 0.2481 - val_accuracy: 0.9202\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 115s 80ms/step - loss: 0.2925 - accuracy: 0.9035 - val_loss: 0.2409 - val_accuracy: 0.9216\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 114s 80ms/step - loss: 0.2989 - accuracy: 0.9004 - val_loss: 0.2468 - val_accuracy: 0.9210\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 115s 80ms/step - loss: 0.2897 - accuracy: 0.9035 - val_loss: 0.2558 - val_accuracy: 0.9170\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 115s 80ms/step - loss: 0.2912 - accuracy: 0.9023 - val_loss: 0.2406 - val_accuracy: 0.9216\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 115s 80ms/step - loss: 0.2930 - accuracy: 0.9037 - val_loss: 0.2504 - val_accuracy: 0.9188\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 116s 81ms/step - loss: 0.2877 - accuracy: 0.9036 - val_loss: 0.2468 - val_accuracy: 0.9182\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 116s 81ms/step - loss: 0.2874 - accuracy: 0.9045 - val_loss: 0.2489 - val_accuracy: 0.9198\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 116s 81ms/step - loss: 0.2743 - accuracy: 0.9073 - val_loss: 0.2373 - val_accuracy: 0.9204\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 117s 81ms/step - loss: 0.2709 - accuracy: 0.9088 - val_loss: 0.2299 - val_accuracy: 0.9222\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 117s 81ms/step - loss: 0.2621 - accuracy: 0.9101 - val_loss: 0.2293 - val_accuracy: 0.9246\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 117s 82ms/step - loss: 0.2646 - accuracy: 0.9098 - val_loss: 0.2352 - val_accuracy: 0.9250\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2626 - accuracy: 0.9089 - val_loss: 0.2276 - val_accuracy: 0.9226\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 117s 82ms/step - loss: 0.2610 - accuracy: 0.9102 - val_loss: 0.2307 - val_accuracy: 0.9248\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2617 - accuracy: 0.9109 - val_loss: 0.2293 - val_accuracy: 0.9246\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2555 - accuracy: 0.9113 - val_loss: 0.2259 - val_accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 117s 82ms/step - loss: 0.2641 - accuracy: 0.9095 - val_loss: 0.2325 - val_accuracy: 0.9228\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2585 - accuracy: 0.9107 - val_loss: 0.2265 - val_accuracy: 0.9242\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2573 - accuracy: 0.9107 - val_loss: 0.2312 - val_accuracy: 0.9232\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2509 - accuracy: 0.9122 - val_loss: 0.2223 - val_accuracy: 0.9234\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2489 - accuracy: 0.9137 - val_loss: 0.2226 - val_accuracy: 0.9232\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 118s 82ms/step - loss: 0.2499 - accuracy: 0.9136 - val_loss: 0.2250 - val_accuracy: 0.9222\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2496 - accuracy: 0.9128 - val_loss: 0.2226 - val_accuracy: 0.9248\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2377 - accuracy: 0.9166 - val_loss: 0.2207 - val_accuracy: 0.9246\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2401 - accuracy: 0.9160 - val_loss: 0.2205 - val_accuracy: 0.9250\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2393 - accuracy: 0.9158 - val_loss: 0.2187 - val_accuracy: 0.9242\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 118s 83ms/step - loss: 0.2393 - accuracy: 0.9166 - val_loss: 0.2187 - val_accuracy: 0.9256\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2403 - accuracy: 0.9151 - val_loss: 0.2185 - val_accuracy: 0.9240\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2371 - accuracy: 0.9167 - val_loss: 0.2186 - val_accuracy: 0.9234\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 119s 83ms/step - loss: 0.2368 - accuracy: 0.9162 - val_loss: 0.2183 - val_accuracy: 0.9246\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 120s 83ms/step - loss: 0.2350 - accuracy: 0.9177 - val_loss: 0.2184 - val_accuracy: 0.9250\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2375 - accuracy: 0.9154 - val_loss: 0.2174 - val_accuracy: 0.9250\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2374 - accuracy: 0.9171 - val_loss: 0.2176 - val_accuracy: 0.9266\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2403 - accuracy: 0.9162 - val_loss: 0.2178 - val_accuracy: 0.9256\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2333 - accuracy: 0.9190 - val_loss: 0.2187 - val_accuracy: 0.9252\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2320 - accuracy: 0.9181 - val_loss: 0.2165 - val_accuracy: 0.9264\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2335 - accuracy: 0.9185 - val_loss: 0.2165 - val_accuracy: 0.9260\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.2322 - accuracy: 0.9174 - val_loss: 0.2164 - val_accuracy: 0.9268\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2344 - accuracy: 0.9172 - val_loss: 0.2164 - val_accuracy: 0.9268\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2307 - accuracy: 0.9193 - val_loss: 0.2160 - val_accuracy: 0.9260\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2318 - accuracy: 0.9188 - val_loss: 0.2154 - val_accuracy: 0.9250\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2314 - accuracy: 0.9189 - val_loss: 0.2160 - val_accuracy: 0.9266\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2298 - accuracy: 0.9189 - val_loss: 0.2157 - val_accuracy: 0.9256\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2305 - accuracy: 0.9196 - val_loss: 0.2155 - val_accuracy: 0.9270\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2278 - accuracy: 0.9193 - val_loss: 0.2155 - val_accuracy: 0.9262\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.2334 - accuracy: 0.9162 - val_loss: 0.2155 - val_accuracy: 0.9268\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 121s 85ms/step - loss: 0.2321 - accuracy: 0.9177 - val_loss: 0.2157 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.resnet.ResNet101(include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "drop = tf.keras.layers.Dropout(0.5)(avg)\n",
    "output = tf.keras.layers.Dense(10, activation=\"softmax\", dtype=\"float32\")(drop)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c8e7fd7-952c-435a-828f-42b1702174ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_v1.keras\")\n",
    "#model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8360fa14-ca8f-4b1e-a8e4-e4c2cc77fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"conv5_block3\"):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e12dc87-7b29-4516-8d50-e07142787bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_conv5_block3_unfreeze.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38aebe98-050a-4cb2-b1b0-4b7f28c613c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 135s 83ms/step - loss: 0.2269 - accuracy: 0.9210 - val_loss: 0.2047 - val_accuracy: 0.9312\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 121s 84ms/step - loss: 0.1473 - accuracy: 0.9481 - val_loss: 0.2286 - val_accuracy: 0.9240\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 128s 88ms/step - loss: 0.0854 - accuracy: 0.9697 - val_loss: 0.2699 - val_accuracy: 0.9262\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 131s 91ms/step - loss: 0.0493 - accuracy: 0.9830 - val_loss: 0.2711 - val_accuracy: 0.9292\n",
      "Epoch 5/100\n",
      "1050/1407 [=====================>........] - ETA: 30s - loss: 0.0230 - accuracy: 0.9929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[55], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mNadam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m)\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m      3\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m----> 4\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b27a82a-b2e5-4dce-bac8-c786646e0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 119s 76ms/step - loss: 2.8964 - accuracy: 0.6910 - val_loss: 3.9165 - val_accuracy: 0.5606\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 117s 81ms/step - loss: 2.7524 - accuracy: 0.7018 - val_loss: 2.7771 - val_accuracy: 0.7220\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 2.6357 - accuracy: 0.7090 - val_loss: 3.2629 - val_accuracy: 0.6712\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 126s 87ms/step - loss: 2.5771 - accuracy: 0.7155 - val_loss: 2.7796 - val_accuracy: 0.7102\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 2.5760 - accuracy: 0.7140 - val_loss: 2.9383 - val_accuracy: 0.6962\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 119s 82ms/step - loss: 1.4006 - accuracy: 0.7751 - val_loss: 1.4671 - val_accuracy: 0.7616\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 123s 85ms/step - loss: 1.4461 - accuracy: 0.7709 - val_loss: 1.3092 - val_accuracy: 0.8222\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 123s 85ms/step - loss: 1.4504 - accuracy: 0.7722 - val_loss: 1.2050 - val_accuracy: 0.8570\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 1.4709 - accuracy: 0.7683 - val_loss: 1.2494 - val_accuracy: 0.8478\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 125s 87ms/step - loss: 1.4614 - accuracy: 0.7701 - val_loss: 1.3419 - val_accuracy: 0.8236\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 1.4624 - accuracy: 0.7710 - val_loss: 1.3070 - val_accuracy: 0.8378\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.9850 - accuracy: 0.8126 - val_loss: 0.8383 - val_accuracy: 0.8764\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.9915 - accuracy: 0.8119 - val_loss: 0.8339 - val_accuracy: 0.8768\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 123s 85ms/step - loss: 0.9890 - accuracy: 0.8126 - val_loss: 0.8566 - val_accuracy: 0.8704\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 1.0014 - accuracy: 0.8078 - val_loss: 0.8596 - val_accuracy: 0.8670\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.9911 - accuracy: 0.8116 - val_loss: 0.8727 - val_accuracy: 0.8694\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 0.7883 - accuracy: 0.8384 - val_loss: 0.6752 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.7857 - accuracy: 0.8390 - val_loss: 0.6837 - val_accuracy: 0.8872\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 125s 87ms/step - loss: 0.7827 - accuracy: 0.8392 - val_loss: 0.6798 - val_accuracy: 0.8868\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.7825 - accuracy: 0.8398 - val_loss: 0.6823 - val_accuracy: 0.8864\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6884 - accuracy: 0.8540 - val_loss: 0.6006 - val_accuracy: 0.8974\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6852 - accuracy: 0.8545 - val_loss: 0.6022 - val_accuracy: 0.8962\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6849 - accuracy: 0.8554 - val_loss: 0.6002 - val_accuracy: 0.9008\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6857 - accuracy: 0.8540 - val_loss: 0.6005 - val_accuracy: 0.8956\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 120s 83ms/step - loss: 0.6866 - accuracy: 0.8533 - val_loss: 0.6014 - val_accuracy: 0.8988\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 123s 86ms/step - loss: 0.6845 - accuracy: 0.8554 - val_loss: 0.6021 - val_accuracy: 0.8986\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 0.6441 - accuracy: 0.8623 - val_loss: 0.5696 - val_accuracy: 0.8988\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 123s 85ms/step - loss: 0.6356 - accuracy: 0.8639 - val_loss: 0.5683 - val_accuracy: 0.8976\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6358 - accuracy: 0.8641 - val_loss: 0.5730 - val_accuracy: 0.8970\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6358 - accuracy: 0.8644 - val_loss: 0.5720 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6361 - accuracy: 0.8669 - val_loss: 0.5753 - val_accuracy: 0.9006\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 124s 86ms/step - loss: 0.6174 - accuracy: 0.8703 - val_loss: 0.5500 - val_accuracy: 0.9002\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 0.6120 - accuracy: 0.8696 - val_loss: 0.5514 - val_accuracy: 0.9008\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 125s 86ms/step - loss: 0.6121 - accuracy: 0.8708 - val_loss: 0.5514 - val_accuracy: 0.8994\n",
      "Epoch 35/100\n",
      " 124/1407 [=>............................] - ETA: 1:36 - loss: 0.6291 - accuracy: 0.8594"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mNadam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m     16\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m     17\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 18\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "base_model = tf.keras.applications.resnet.ResNet101(include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "drop = tf.keras.layers.Dropout(0.6)(avg)\n",
    "output = tf.keras.layers.Dense(10, activation=\"softmax\", dtype=\"float32\", kernel_regularizer=l2(0.1))(drop)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_l2_freeze_all.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a818b9fc-fc2e-405b-8eef-b311f3365f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 142s 91ms/step - loss: 0.5017 - accuracy: 0.8878 - val_loss: 0.4233 - val_accuracy: 0.9102\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 141s 97ms/step - loss: 0.3453 - accuracy: 0.9319 - val_loss: 0.3572 - val_accuracy: 0.9236\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 143s 99ms/step - loss: 0.2533 - accuracy: 0.9570 - val_loss: 0.3772 - val_accuracy: 0.9176\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 144s 99ms/step - loss: 0.1859 - accuracy: 0.9750 - val_loss: 0.3870 - val_accuracy: 0.9190\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 149s 103ms/step - loss: 0.1489 - accuracy: 0.9831 - val_loss: 0.3697 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 151s 104ms/step - loss: 0.0891 - accuracy: 0.9934 - val_loss: 0.2829 - val_accuracy: 0.9360\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 149s 103ms/step - loss: 0.0585 - accuracy: 0.9987 - val_loss: 0.2755 - val_accuracy: 0.9376\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0475 - accuracy: 0.9996 - val_loss: 0.2953 - val_accuracy: 0.9330\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 151s 104ms/step - loss: 0.0386 - accuracy: 0.9999 - val_loss: 0.2520 - val_accuracy: 0.9386\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 152s 105ms/step - loss: 0.0548 - accuracy: 0.9977 - val_loss: 0.2554 - val_accuracy: 0.9384\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 150s 104ms/step - loss: 0.0403 - accuracy: 0.9988 - val_loss: 0.2459 - val_accuracy: 0.9402\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 144s 100ms/step - loss: 0.0302 - accuracy: 0.9997 - val_loss: 0.2246 - val_accuracy: 0.9420\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 148s 102ms/step - loss: 0.0395 - accuracy: 0.9987 - val_loss: 0.2822 - val_accuracy: 0.9382\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 150s 103ms/step - loss: 0.0409 - accuracy: 0.9983 - val_loss: 0.2349 - val_accuracy: 0.9422\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0242 - accuracy: 0.9998 - val_loss: 0.2445 - val_accuracy: 0.9404\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 148s 102ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9438\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 152s 104ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9438\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 152s 105ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9446\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 152s 105ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9462\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 147s 102ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9450\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9428\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9438\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 145s 100ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9478\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9460\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 146s 101ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9466\n",
      "Epoch 26/100\n",
      " 510/1407 [=========>....................] - ETA: 1:21 - loss: 0.0084 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mNadam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m     12\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 13\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_l2_freeze_all.keras\")\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"conv5_block3\"):\n",
    "        layer.trainable = True\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_l2_conv5_unfreeze.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc4947ee-4099-47d3-b8ae-253eadf6b475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 183s 121ms/step - loss: 0.0138 - accuracy: 0.9996 - val_loss: 0.2171 - val_accuracy: 0.9470\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 171s 119ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9484\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 172s 119ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9500\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 172s 119ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9492\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 172s 120ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9488\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 172s 120ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9486\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 174s 121ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9504\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 174s 121ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9524\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 177s 123ms/step - loss: 0.0086 - accuracy: 0.9999 - val_loss: 0.1855 - val_accuracy: 0.9510\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 176s 122ms/step - loss: 0.0084 - accuracy: 0.9999 - val_loss: 0.1879 - val_accuracy: 0.9512\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 174s 121ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9516\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 173s 120ms/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.1861 - val_accuracy: 0.9508\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 173s 120ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9506\n",
      "Epoch 14/100\n",
      " 122/1407 [=>............................] - ETA: 2:18 - loss: 0.0076 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mNadam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m     12\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 13\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_l2_conv5_unfreeze.keras\")\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"conv5\"):\n",
    "        layer.trainable = True\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_l2_conv5_unfreeze_all.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34dec718-64b5-4fdf-87b4-a898756b9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 567s 345ms/step - loss: 0.0550 - accuracy: 0.9861 - val_loss: 0.1731 - val_accuracy: 0.9514\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 496s 347ms/step - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.1629 - val_accuracy: 0.9548\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 506s 354ms/step - loss: 0.0102 - accuracy: 0.9999 - val_loss: 0.1628 - val_accuracy: 0.9574\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 499s 348ms/step - loss: 0.0098 - accuracy: 0.9999 - val_loss: 0.1656 - val_accuracy: 0.9580\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 506s 355ms/step - loss: 0.0104 - accuracy: 0.9997 - val_loss: 0.1645 - val_accuracy: 0.9562\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 509s 356ms/step - loss: 0.0110 - accuracy: 0.9995 - val_loss: 0.1643 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 525s 368ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.1473 - val_accuracy: 0.9626\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 540s 379ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9614\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 514s 358ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9622\n",
      "Epoch 10/100\n",
      " 367/1407 [======>.......................] - ETA: 5:54 - loss: 0.0078 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mNadam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[0;32m     10\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 11\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 917\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    919\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    920\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"conv4\"):\n",
    "        layer.trainable = True\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_l2_conv4_unfreeze.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, lr_scheduler_cb]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3035e13-948d-4e7b-a742-1c1a9c1d6914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 24s 69ms/step - loss: 0.1520 - accuracy: 0.9613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15199005603790283, 0.9613000154495239]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_l2_conv4_unfreeze.keras\")\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529bd30-fc7b-49fa-b226-a812600bfcf8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After a day of training and tweaking parameters, I've concluded that selecting a complex model for CIFAR-10 was a mistake. I primarily struggled with overfitting and regret skipping the data augmentation step, which definitely could have mitigated this issue. Additionally, I encountered several out-of-memory (OOM) errors. To address these, I tried various methods; reducing the batch size helped, but it came at the cost of lower accuracy. A more effective solution was setting the mixed precision policy, which did not impact the model's performance.\n",
    "\n",
    "Ultimately, I documented the steps for the solution that worked best. To combat the overfitting problems, I used L2 and Dropout regularization methods, which address the issue from different angles. Achieving a test loss of 0.151 and an accuracy of 96.1% is a satisfactory outcome, considering the lack of data augmentation and the initially unsuitable architecture choice. Moving forward, I plan to design my own Residual block and train CIFAR-10 using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18143d3a-9eea-4b5c-a4f1-f7e6c519099d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
